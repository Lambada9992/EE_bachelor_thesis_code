{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### imports\n",
    "\n",
    "FetchModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.ao.quantization import (\n",
    "  get_default_qconfig_mapping,\n",
    "  get_default_qat_qconfig_mapping,\n",
    "  QConfigMapping,\n",
    ")\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "import copy\n",
    "\n",
    "print(torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T20:57:02.948643Z",
     "end_time": "2023-04-23T20:57:02.963344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchvision.models.list_models()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T18:15:37.141114Z",
     "end_time": "2023-04-22T18:15:37.154708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "MobileNetV2(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6(inplace=True)\n    )\n    (1): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (2): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (3): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (4): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (8): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (9): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (10): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (11): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (12): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (13): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (14): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (15): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (16): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (17): InvertedResidual(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU6(inplace=True)\n        )\n        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (18): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU6(inplace=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=False)\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\n  )\n)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "model.eval()\n",
    "\n",
    "# model.half()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T19:26:52.833749Z",
     "end_time": "2023-04-22T19:26:52.947188Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert model to ptl file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"rsqrt_cpu\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m traced_script_module \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mscript(model)\n\u001B[0;32m----> 2\u001B[0m traced_script_module_optimized \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_for_mobile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraced_script_module\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m traced_script_module_optimized\u001B[38;5;241m.\u001B[39m_save_for_lite_interpreter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_fp16.ptl\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/mydev/WUT_EE_bachelor_thesis_code/Pytorch/venv/lib/python3.10/site-packages/torch/utils/mobile_optimizer.py:62\u001B[0m, in \u001B[0;36moptimize_for_mobile\u001B[0;34m(script_module, optimization_blocklist, preserved_methods, backend)\u001B[0m\n\u001B[1;32m     60\u001B[0m backend \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mlower()\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 62\u001B[0m     optimized_cpp_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jit_pass_optimize_for_mobile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscript_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimization_blocklist\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreserved_methods_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m backend \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvulkan\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     67\u001B[0m     optimized_cpp_module \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_jit_pass_vulkan_optimize_for_mobile(\n\u001B[1;32m     68\u001B[0m         script_module\u001B[38;5;241m.\u001B[39m_c,\n\u001B[1;32m     69\u001B[0m         optimization_blocklist,\n\u001B[1;32m     70\u001B[0m         preserved_methods_str)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \"rsqrt_cpu\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "traced_script_module = torch.jit.script(model)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"model_fp16.ptl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T15:55:12.215478Z",
     "end_time": "2023-04-22T15:55:14.457692Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "quantization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model_to_quantize = copy.deepcopy(model)\n",
    "model_to_quantize.eval()\n",
    "qconfig_mapping = get_default_qconfig_mapping(\"qnnpack\")\n",
    "qconfig_dict = {\"\": qconfig_mapping}\n",
    "# qconfig_dict[\"\"].weight_dtype = torch.float16\n",
    "\n",
    "example_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "model_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_mapping, example_input)\n",
    "\n",
    "calibration_data = [torch.randn(1, 3, 224, 224) for _ in range(100)]\n",
    "for i in range(len(calibration_data)):\n",
    "   model_prepared(calibration_data[i])\n",
    "\n",
    "\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T18:17:07.494720Z",
     "end_time": "2023-04-22T18:17:21.215317Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcin.bobinski/mydev/WUT_EE_bachelor_thesis_code/Pytorch/venv/lib/python3.10/site-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "traced_script_module = torch.jit.script(model_quantized)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"model_quantized.ptl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T18:17:29.847272Z",
     "end_time": "2023-04-22T18:17:31.229344Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_to_quantize = copy.deepcopy(model)\n",
    "model_fused = quantize_fx.fuse_fx(model_to_quantize)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "snipets of code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx\n",
    "from torchvision.models import resnet50\n",
    "fp32_model = resnet50().eval()\n",
    "model = copy.deepcopy(fp32_model)\n",
    "# `qconfig` means quantization configuration, it specifies how should we\n",
    "# observe the activation and weight of an operator\n",
    "# `qconfig_dict`, specifies the `qconfig` for each operator in the model\n",
    "# we can specify `qconfig` for certain types of modules\n",
    "# we can specify `qconfig` for a specific submodule in the model\n",
    "# we can specify `qconfig` for some functioanl calls in the model\n",
    "# we can also set `qconfig` to None to skip quantization for some operators\n",
    "qconfig = get_default_qconfig(\"fbgemm\")\n",
    "qconfig_dict = {\"\": qconfig}\n",
    "# `prepare_fx` inserts observers in the model based on the configuration in `qconfig_dict`\n",
    "model_prepared = prepare_fx(model, qconfig_dict)\n",
    "# calibration runs the model with some sample data, which allows observers to record the statistics of\n",
    "# the activation and weigths of the operators\n",
    "calibration_data = [torch.randn(1, 3, 224, 224) for _ in range(100)]\n",
    "for i in range(len(calibration_data)):\n",
    "   model_prepared(calibration_data[i])\n",
    "# `convert_fx` converts a calibrated model to a quantized model, this includes inserting\n",
    "# quantize, dequantize operators to the model and swap floating point operators with quantized operators\n",
    "model_quantized = convert_fx(copy.deepcopy(model_prepared))\n",
    "# benchmark\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "%timeit fp32_model(x)\n",
    "%timeit model_quantized(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torchvision.models.alexnet()\n",
    "torchvision.models.convnext_base()\n",
    "torchvision.models.convnext_large()\n",
    "torchvision.models.convnext_small()\n",
    "torchvision.models.convnext_tiny()\n",
    "torchvision.models.deeplabv3_mobilenet_v3_large()\n",
    "torchvision.models.deeplabv3_resnet101()\n",
    "torchvision.models.deeplabv3_resnet50()\n",
    "torchvision.models.densenet121()\n",
    "torchvision.models.densenet161()\n",
    "torchvision.models.densenet169()\n",
    "torchvision.models.densenet201()\n",
    "torchvision.models.efficientnet_b0()\n",
    "torchvision.models.efficientnet_b1()\n",
    "torchvision.models.efficientnet_b2()\n",
    "torchvision.models.efficientnet_b3()\n",
    "torchvision.models.efficientnet_b4()\n",
    "torchvision.models.efficientnet_b5()\n",
    "torchvision.models.efficientnet_b6()\n",
    "torchvision.models.efficientnet_b7()\n",
    "torchvision.models.efficientnet_v2_l()\n",
    "torchvision.models.efficientnet_v2_m()\n",
    "torchvision.models.efficientnet_v2_s()\n",
    "torchvision.models.fasterrcnn_mobilenet_v3_large_320_fpn()\n",
    "torchvision.models.fasterrcnn_mobilenet_v3_large_fpn()\n",
    "torchvision.models.fasterrcnn_resnet50_fpn()\n",
    "torchvision.models.fasterrcnn_resnet50_fpn_v2()\n",
    "torchvision.models.fcn_resnet101()\n",
    "torchvision.models.fcn_resnet50()\n",
    "torchvision.models.fcos_resnet50_fpn()\n",
    "torchvision.models.googlenet()\n",
    "torchvision.models.inception_v3()\n",
    "torchvision.models.keypointrcnn_resnet50_fpn()\n",
    "torchvision.models.lraspp_mobilenet_v3_large()\n",
    "torchvision.models.maskrcnn_resnet50_fpn()\n",
    "torchvision.models.maskrcnn_resnet50_fpn_v2()\n",
    "torchvision.models.maxvit_t()\n",
    "torchvision.models.mc3_18()\n",
    "torchvision.models.mnasnet0_5()\n",
    "torchvision.models.mnasnet0_75()\n",
    "torchvision.models.mnasnet1_0()\n",
    "torchvision.models.mnasnet1_3()\n",
    "torchvision.models.mobilenet_v2()\n",
    "torchvision.models.mobilenet_v3_large()\n",
    "torchvision.models.mobilenet_v3_small()\n",
    "torchvision.models.mvit_v1_b()\n",
    "torchvision.models.mvit_v2_s()\n",
    "torchvision.models.quantized_googlenet()\n",
    "torchvision.models.quantized_inception_v3()\n",
    "torchvision.models.quantized_mobilenet_v2()\n",
    "torchvision.models.quantized_mobilenet_v3_large()\n",
    "torchvision.models.quantized_resnet18()\n",
    "torchvision.models.quantized_resnet50()\n",
    "torchvision.models.quantized_resnext101_32x8d()\n",
    "torchvision.models.quantized_resnext101_64x4d()\n",
    "torchvision.models.quantized_shufflenet_v2_x0_5()\n",
    "torchvision.models.quantized_shufflenet_v2_x1_0()\n",
    "torchvision.models.quantized_shufflenet_v2_x1_5()\n",
    "torchvision.models.quantized_shufflenet_v2_x2_0()\n",
    "torchvision.models.r2plus1d_18()\n",
    "torchvision.models.r3d_18()\n",
    "torchvision.models.raft_large()\n",
    "torchvision.models.raft_small()\n",
    "torchvision.models.regnet_x_16gf()\n",
    "torchvision.models.regnet_x_1_6gf()\n",
    "torchvision.models.regnet_x_32gf()\n",
    "torchvision.models.regnet_x_3_2gf()\n",
    "torchvision.models.regnet_x_400mf()\n",
    "torchvision.models.regnet_x_800mf()\n",
    "torchvision.models.regnet_x_8gf()\n",
    "torchvision.models.regnet_y_128gf()\n",
    "torchvision.models.regnet_y_16gf()\n",
    "torchvision.models.regnet_y_1_6gf()\n",
    "torchvision.models.regnet_y_32gf()\n",
    "torchvision.models.regnet_y_3_2gf()\n",
    "torchvision.models.regnet_y_400mf()\n",
    "torchvision.models.regnet_y_800mf()\n",
    "torchvision.models.regnet_y_8gf()\n",
    "torchvision.models.resnet101()\n",
    "torchvision.models.resnet152()\n",
    "torchvision.models.resnet18()\n",
    "torchvision.models.resnet34()\n",
    "torchvision.models.resnet50()\n",
    "torchvision.models.resnext101_32x8d()\n",
    "torchvision.models.resnext101_64x4d()\n",
    "torchvision.models.resnext50_32x4d()\n",
    "torchvision.models.retinanet_resnet50_fpn()\n",
    "torchvision.models.retinanet_resnet50_fpn_v2()\n",
    "torchvision.models.s3d()\n",
    "torchvision.models.shufflenet_v2_x0_5()\n",
    "torchvision.models.shufflenet_v2_x1_0()\n",
    "torchvision.models.shufflenet_v2_x1_5()\n",
    "torchvision.models.shufflenet_v2_x2_0()\n",
    "torchvision.models.squeezenet1_0()\n",
    "torchvision.models.squeezenet1_1()\n",
    "torchvision.models.ssd300_vgg16()\n",
    "torchvision.models.ssdlite320_mobilenet_v3_large()\n",
    "torchvision.models.swin3d_b()\n",
    "torchvision.models.swin3d_s()\n",
    "torchvision.models.swin3d_t()\n",
    "torchvision.models.swin_b()\n",
    "torchvision.models.swin_s()\n",
    "torchvision.models.swin_t()\n",
    "torchvision.models.swin_v2_b()\n",
    "torchvision.models.swin_v2_s()\n",
    "torchvision.models.swin_v2_t()\n",
    "torchvision.models.vgg11()\n",
    "torchvision.models.vgg11_bn()\n",
    "torchvision.models.vgg13()\n",
    "torchvision.models.vgg13_bn()\n",
    "torchvision.models.vgg16()\n",
    "torchvision.models.vgg16_bn()\n",
    "torchvision.models.vgg19()\n",
    "torchvision.models.vgg19_bn()\n",
    "torchvision.models.vit_b_16()\n",
    "torchvision.models.vit_b_32()\n",
    "torchvision.models.vit_h_14()\n",
    "torchvision.models.vit_l_16()\n",
    "torchvision.models.vit_l_32()\n",
    "torchvision.models.wide_resnet101_2()\n",
    "torchvision.models.wide_resnet50_2()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
